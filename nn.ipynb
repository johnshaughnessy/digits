{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdfc866e-52c5-4ec5-b889-78b88c449569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.vision.all import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bebf898-6c7d-442c-9ef0-dd951d604766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Data Preparation\n",
    "path = untar_data(URLs.MNIST)\n",
    "\n",
    "dls = ImageDataLoaders.from_folder(path, train='training', valid='testing', convert_mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59af76-2905-4a64-b60c-626871c6f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3c35632-b5f3-4623-ae32-e687037ef135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Model Definition\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3*28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "556b919c-73eb-4e88-bfab-6d88a5b77957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Loss and Optimizer\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = MyModel().to(device)\n",
    "opt = SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6f3ea76-ac8a-4434-abd1-76a9798db793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in dls.train:\n",
    "    print(xb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b151516-d7df-4651-97b4-257ac600495d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no implementation found for 'torch.nn.functional.cross_entropy' on types that implement __torch_function__: [<class 'fastai.torch_core.TensorImage'>, <class 'fastai.torch_core.TensorCategory'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m dls\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[1;32m      7\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(xb)\n\u001b[0;32m----> 8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     10\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/mambaforge/envs/scratch/lib/python3.10/site-packages/torch/nn/functional.py:3015\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2949\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"This criterion computes the cross entropy loss between input logits and target.\u001b[39;00m\n\u001b[1;32m   2950\u001b[0m \n\u001b[1;32m   2951\u001b[0m \u001b[38;5;124;03mSee :class:`~torch.nn.CrossEntropyLoss` for details.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;124;03m    >>> loss.backward()\u001b[39;00m\n\u001b[1;32m   3013\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight):\n\u001b[0;32m-> 3015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_average\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n",
      "File \u001b[0;32m~/mambaforge/envs/scratch/lib/python3.10/site-packages/torch/overrides.py:1563\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1562\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m nor in mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_current_function_mode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1563\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mTypeError\u001b[0m: no implementation found for 'torch.nn.functional.cross_entropy' on types that implement __torch_function__: [<class 'fastai.torch_core.TensorImage'>, <class 'fastai.torch_core.TensorCategory'>]"
     ]
    }
   ],
   "source": [
    "# export\n",
    "# Training Loop\n",
    "epochs = 10  # Number of epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for xb, yb in dls.train:\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No gradient calculation needed\n",
    "        val_loss = sum(F.cross_entropy(model(xb), yb) for xb, yb in dls.valid)\n",
    "        val_loss /= len(dls.valid)\n",
    "        \n",
    "    # Evaluate training and validation accuracy\n",
    "    def batch_accuracy(xb, yb):\n",
    "        preds = xb.argmax(dim=1)\n",
    "        return (preds == yb).float().mean()\n",
    "    \n",
    "    train_acc = sum(batch_accuracy(model(xb), yb) for xb, yb in dls.train) / len(dls.train)\n",
    "    valid_acc = sum(batch_accuracy(model(xb), yb) for xb, yb in dls.valid) / len(dls.valid)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Training Loss: {loss}, Validation Loss: {val_loss}, Training Acc: {train_acc}, Validation Acc: {valid_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4737bcc7-d27a-4d33-976a-199b0a0015cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "def export_cells(notebook_path, export_path, directive=\"# export\"):\n",
    "    with open(notebook_path, 'r') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "    script_lines = []\n",
    "    script_lines.append(\"# Generated by the corresponding notebook.\")\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == \"code\":\n",
    "            if cell.source.startswith(directive):\n",
    "                # Remove the first line (the directive itself)\n",
    "                cleaned_source = \"\\n\".join(cell.source.split(\"\\n\")[1:])\n",
    "                script_lines.append(cleaned_source)\n",
    "\n",
    "    with open(export_path, 'w') as f:\n",
    "        f.write(\"\\n\\n\".join(script_lines))\n",
    "\n",
    "# Usage\n",
    "export_cells(\"nn.ipynb\", \"nn.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bbd8e-3c9b-4285-bf70-a9279408c9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
