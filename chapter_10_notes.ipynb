{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a017ae17-2ce3-4067-a2eb-ead4718e4e5f",
   "metadata": {},
   "source": [
    "# Chapter 10 Questionairre\n",
    "\n",
    "First I'll write all the questions and make a guess at their answers.\n",
    "Then as I read through the chapter, I'll write answers more confidently.\n",
    "Finally, I'll compare my guesses with my better answers to see where I was right, wrong or had misconceptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55973bd-4f4d-4f00-b76a-c809b71c6a94",
   "metadata": {},
   "source": [
    "## What is self-supervised learning?\n",
    "\n",
    "Self-supervised learning refers to a training process where the labels or information you need to predict the output is in the input data itself. For example if you are training a model to predict the next word of some text, you can give it a bunch of text so that it trains just on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4086588-3b4c-44f1-ae52-fdb1cba9d7a3",
   "metadata": {},
   "source": [
    "## What is a language model?\n",
    "\n",
    "A language model is a model that is trained to predict the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ff18e-e85c-4376-aad2-d1efd382218e",
   "metadata": {},
   "source": [
    "## Why is a language model considered to be self-supervised?\n",
    "\n",
    "Because to train it you just give it a bunch of unlabeled text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a6fcb-3177-43a8-80c4-62b91b180372",
   "metadata": {},
   "source": [
    "## What are self-supervised models usually used for?\n",
    "\n",
    "Guess: Language models and any problem where we have enough data and we can get good enough results without manually coming up with labels for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0ffe8-8833-4b5a-a67b-33cf451931dd",
   "metadata": {},
   "source": [
    "## Why do we fine-tune language models?\n",
    "\n",
    "Guess: We fine-tune language models because we get big gains from transfer-learning from a pre-trained model, but usually we want a model to be able to do some more specific task really well. Fine-tuning allows us to benefit from the pre-trained model while still getting good results (without having to start from scratch) on the more specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc543f-be50-4e82-8024-db974215e339",
   "metadata": {},
   "source": [
    "## What are the three steps to create a state-of-the-art text classifier?\n",
    "\n",
    "Guess: Get a pretrained large language model, get a labeled dataset, fine tune the model on that dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1ff33-97fe-45f3-8264-b11df509d3b9",
   "metadata": {},
   "source": [
    "## How do the 50,000 unlabeled movie reviews help create a better text classifier for the IMDb dataset?\n",
    "\n",
    "Guess: If you use a pretrained language model, maybe it can already determine whether reviews are positive or negative? And maybe reviews tend to be about positive/negative comments more so than other sources like wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8402d97-263f-4999-a66e-6596a9ae43ce",
   "metadata": {},
   "source": [
    "## What are the three steps to prepare your data for a large language model?\n",
    "\n",
    "Guess: Tokenization, Positional Encoding, Embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd0a13a-90b7-4cec-ade4-97c8b2bf9aec",
   "metadata": {},
   "source": [
    "## What is tokenization? Why do we need it?\n",
    "\n",
    "Guess: Tokenization is transforming strings of characters into sequences of tokens. We need this because our models work on numbers, and typically we don't want to use just unicode characters for tokens, we want something closer to words or sub-words. Too many entries in our vocabulary make for too much memory. Too few entries in our vocabulary mean the model has to be really, really big. Or something like that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f036442-ae12-4613-a307-c4566bbf8286",
   "metadata": {},
   "source": [
    "## Name three approaches to tokenization\n",
    "\n",
    "Guess: Byte-pair encoding, character encoding, word encoding?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94b9c2-81e7-4cf4-ad7b-c0dace22f088",
   "metadata": {},
   "source": [
    "## What is `xxbos`?\n",
    "\n",
    "Guess: It's a nickname for shoggoth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645774f8-ab82-4c23-a898-b08a2ee5caca",
   "metadata": {},
   "source": [
    "## List four rules that fastai applies to text during tokenization.\n",
    "\n",
    "Guess: Capitalization, start of word, start of sentence, something about repeated characters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8cc88-5695-40f6-95ce-5452737bacc8",
   "metadata": {},
   "source": [
    "## Why are repeated characters replaced with a token showing the number of repititions and the character that's repeated?\n",
    "\n",
    "Guess: Maybe we want typos to be treated the same way that non-typos are treated? If I say \"helllo\" instead of \"hello\", maybe this encoding helps coerce them to the same thing? Or maybe it's just to save space?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7021a5-c4f3-4e85-8481-4c7c09980e6a",
   "metadata": {},
   "source": [
    "## What is numericalization?\n",
    "\n",
    "Guess: Something about turning things into numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f7033-a10a-4e38-88b7-c41bb3b08aa2",
   "metadata": {},
   "source": [
    "## Why might there be words that are replaced with the \"unknown word\" token?\n",
    "\n",
    "Guess: If there's some word like \"jdkslals\" that isn't in our vocabulary, we still need to put _something_ into the vector. So this is replaced with an \"unknown word\" token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef95799f-ddb0-4ca0-acdf-1e59e30eba2b",
   "metadata": {},
   "source": [
    "## With a batch size of 64, the first row of the tensor representing the first batch contains the first 64 tokens for the dataset. What does the second row of that tensor contain? What does the first row of the second batch contain?\n",
    "\n",
    "Guess: The tensor represents the first batch, so I'm guessing those 64 tokens in the first row are the first tokens of separate inputs. Then the second row of that tensor (representing the first batch) would be the second tokens of each of the first 64 inputs. Then the first row of the second batch would be the first tokens of each of the inputs in the second batch: inputs 65-128."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92763bd0-3fe5-4efa-9772-cc6a4e3d483c",
   "metadata": {},
   "source": [
    "## Why do we need padding for text classification? Why don't we need it for language modeling?\n",
    "\n",
    "Guess: I don't know what language modeling is, but I'm guessing that the need for padding has to do with matrix multiplication needing to be against the vectors / tensors of compatible shapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07bbdf-108f-4f33-8769-920f2c9b5416",
   "metadata": {},
   "source": [
    "## What does an embedding matrix for NLP contain? What is its shape?\n",
    "\n",
    "Guess: Hmm... Maybe an embedding matrix creates an embedding? So maybe its shape is ROWS = max # of tokens allowed in a tokenized input and COLUMNS = size of embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f216a62-6386-43fb-9b16-6e89aab4dcc7",
   "metadata": {},
   "source": [
    "## What is perplexity?\n",
    "\n",
    "Guess: No idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e31df-b151-4bb0-b3c3-cbe44c57ce37",
   "metadata": {},
   "source": [
    "## Why do we have to pass the vocabulary of the language model to the classifier data block?\n",
    "\n",
    "Guess: At some point maybe we need to transform vector embeddings back into something human-readable? Or maybe the classifier data block (whatever that is) is trained on our vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c2cd6-984f-4fd5-8966-d5124fa33f6e",
   "metadata": {},
   "source": [
    "## What is gradual unfreezing?\n",
    "\n",
    "Guess: I'm guessing this has to do with taking a pre-trained model, freezing the initial layers while you fine tune some NEW layers, and then gradually unfreezing layers (starting from the back) as you need to fine-tune things further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9da13-55a2-4d28-9db9-7c436c007684",
   "metadata": {},
   "source": [
    "## Why is text generation always likely to be ahead of automatic identification of machine-generated texts?\n",
    "\n",
    "Guess: Maybe it's easy to train machine-generation algorithms to beat whatever the identification model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510afab0-3e4b-427c-bf0d-ff079b7c39d3",
   "metadata": {},
   "source": [
    "## See what you can learn about language models and disinformation. What are the best language models today? Take a look at some of their outputs. Do you find them convincing? How could a bad actor best use such a model to create conflict and uncertainty?\n",
    "\n",
    "Guess: GPT4, Bard (?), Llama 2 (?). I find them \"convincing\" in so far as they can generate lots of reasonable text and images. If someone wanted to spread misinformation they easily could generate \"evidence\" of whatever they are claiming. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c5846-bf4d-4b8d-b81c-17663a20136f",
   "metadata": {},
   "source": [
    "## Given the limitations that models are unlikely to be able to consistently recognize machine-generated texts, what other approaches may be needed to handle large-scale disinformation campaigns that leverage deep learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9648b52-b46a-4fc2-a4a5-cad66a9d3112",
   "metadata": {},
   "source": [
    "Guess: I am guessing we will need to refine our thinking and infrastructure and capabilities with respect to how we trust and verify information, and my guess is that it will be incredibly disorganized and bleak until we do (with adoption, etc). I don't know what this looks like, but I want something like a weighted chain of trust between me and other people that I know. When I don't trust someone's views, I want my distrust of their trust scores to be reflected somehow. In other words, I want to create some kind of social model where trustworthy people earn trust across the network and untrusty people lose trust. And trust is not a single score assigned to people, it's like a high-dimensional vector that reflects the world's belief in their perspective across various topics / events in question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e8e8f-0e69-4dc9-8bee-5b8fb4c6ad11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c1ffdee-548e-4e02-8ec9-ba70d35f1eb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed8dd8f-7ef2-4c6c-bcd3-afaad5ccaae9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6be54da1-889e-4101-941d-6de676003cd9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11435930-232e-4154-9551-16aee7e7c3d6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
