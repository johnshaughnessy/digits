# Generated by the corresponding notebook.

import fastbook
fastbook.setup_book()

from fastai.vision.all import *
from fastbook import *

path = untar_data(URLs.MNIST)


def stack(dir):
    return torch.stack([tensor(Image.open(f)) for f in dir.ls()]).float()/255

samples = [tensor(Image.open(files.ls()[0])) for files in (path/'training').ls().sorted()]
stacks = [stack(dir) for dir in (path/'training').ls().sorted()]
means = [s.mean(0) for s in stacks]

def mnist_distance(a,b):
    return (a-b).abs().mean((-1,-2))

labels = ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]

def scores(sample):
    return [mnist_distance(sample, mean) for mean in means] 

import numpy as np
def classify(scores):
    return labels[np.argmin(scores)]


# Transform from list of matrices to list of arrays
train_x = torch.cat(stacks).view(-1, 28*28)
def filecount(dir):
    return len(dir.ls())
train_y = torch.cat([tensor([i]*filecount(path/'training'/f'{i}')) for i in range(10)]).unsqueeze(1)

valid_stacks = [stack(dir) for dir in (path/'testing').ls().sorted()]
valid_x = torch.cat(valid_stacks).view(-1, 28*28)
valid_y = torch.cat([tensor([i]*filecount(path/'testing'/f'{i}')) for i in range(10)]).unsqueeze(1)

dset = list(zip(train_x, train_y))
valid_dset = list(zip(valid_x, valid_y))

def init_params(size, std=1.0):
    return (torch.randn(size)*std).requires_grad_()

weights = init_params((28*28,1))
bias = init_params(1)

def mnist_loss(predictions, targets):
    predictions = predictions.sigmoid()
    return torch.where(targets==1, 
                       
def calc_grad(xb, yb, model):
    preds = model(xb)
    loss = mnist_loss(preds, yb)
    loss.backward()